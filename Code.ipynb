{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library\n",
    "\n",
    "This section imports required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T19:15:13.974834Z",
     "iopub.status.busy": "2021-06-07T19:15:13.974417Z",
     "iopub.status.idle": "2021-06-07T19:15:13.981141Z",
     "shell.execute_reply": "2021-06-07T19:15:13.980339Z",
     "shell.execute_reply.started": "2021-06-07T19:15:13.974799Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import random as r\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.linear_model import HuberRegressor, Ridge, TheilSenRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import copy\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files From Path\n",
    "\n",
    "This section reads files and converts to NumPy array from Pandas Dataframe. \n",
    "\n",
    "## Inputs: No Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T19:15:14.574876Z",
     "iopub.status.busy": "2021-06-07T19:15:14.574279Z",
     "iopub.status.idle": "2021-06-07T19:15:14.764382Z",
     "shell.execute_reply": "2021-06-07T19:15:14.763336Z",
     "shell.execute_reply.started": "2021-06-07T19:15:14.574824Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data_from_file():\n",
    "    path = \"Data/\"\n",
    "    train_t0_df = pd.read_csv(path + \"train_t0.csv\")\n",
    "    train_t1_df = pd.read_csv(path + \"train_t1.csv\")\n",
    "    test_t0_df = pd.read_csv(path + \"test_t0.csv\")    \n",
    "    train_t0 = train_t0_df.to_numpy()[:,1:]\n",
    "    train_t1 = train_t1_df.to_numpy()[:,1:]\n",
    "    test_t0 = test_t0_df.to_numpy()[:,1:]\n",
    "    \n",
    "    return train_t0,train_t1,test_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Eliminations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_outliers(train_t0,train_t1):\n",
    "    \n",
    "    out = LocalOutlierFactor(n_neighbors=30)\n",
    "    il_ind = np.where(out.fit_predict(train_t0) == 1)\n",
    "    train_t0_il = train_t0[il_ind]\n",
    "    train_t1_il = train_t1[il_ind]\n",
    "    return train_t0_il,train_t1_il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction(train_t0,test_t0):\n",
    "    transformer = PCA(n_components=21)\n",
    "    X_train = transformer.fit_transform(train_t0)\n",
    "    X_test = transformer.transform(test_t0)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train_t0,train_t1,test_t0):\n",
    "    scaler = StandardScaler()\n",
    "    train_t0_transformed = scaler.fit_transform(train_t0)\n",
    "    train_t1_transformed = scaler.transform(train_t1)\n",
    "    test_t0_transformed = scaler.transform(test_t0)\n",
    "    return train_t0_transformed, train_t1_transformed, test_t0_transformed, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backscale_data(test_t0,scaler):\n",
    "    return scaler.inverse_transform(test_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_t0,train_t1,test_t0):\n",
    "    train_t0_el, train_t1_el = eliminate_outliers(train_t0,train_t1)\n",
    "#     train_t0_reducted, test_t0_reducted = dim_reduction(train_t0_el,test_t0)\n",
    "    return train_t0_el, train_t1_el, test_t0, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(t0_train,t1_train,model):\n",
    "    \n",
    "    models=[]\n",
    "    for i in range(t0_train.shape[1]):\n",
    "        clf = copy.deepcopy(model)\n",
    "        \n",
    "        clf.fit(t0_train[:,i].reshape(-1,1),t1_train[:,i].reshape(-1,1))\n",
    "        models.append(clf)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(train_t0,train_t1):\n",
    "    models = [ \n",
    "            Ridge(alpha = 5*1e-2), \n",
    "            TheilSenRegressor(random_state=0,n_subsamples = 20), \n",
    "            HuberRegressor(alpha = 5*1e-2)\n",
    "    ]\n",
    "    \n",
    "    ret_models = []\n",
    "    i = 0\n",
    "    for model in models:\n",
    "        if (i == 0):\n",
    "            train_t0_il,train_t1_il = eliminate_outliers(train_t0,train_t1)\n",
    "            models_curr_mod = train_model(train_t0_il,train_t1_il,model)\n",
    "            ret_models.append(models_curr_mod)\n",
    "            i+=1\n",
    "        else:\n",
    "            models_curr_mod = train_model(train_t0,train_t1,model)\n",
    "            ret_models.append(models_curr_mod)\n",
    "        \n",
    "    return ret_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(t0_test,clfs):\n",
    "    \n",
    "    predictions=[]\n",
    "    for i in range(len(clfs)):\n",
    "        pred = clfs[i].predict(t0_test[:,i].reshape(-1,1))\n",
    "        predictions.append(pred.T)\n",
    "    \n",
    "    predictions=np.transpose(np.array(predictions)).reshape(-1,len(t0_test[0]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(test_t0,models):\n",
    "    y_test_results = []\n",
    "        \n",
    "    for model in models:\n",
    "        y_test = predict_model(test_t0,model)\n",
    "        y_test_results.append(y_test)\n",
    "        \n",
    "    y_test1 =  y_test_results[0]\n",
    "    y_test2 =  y_test_results[1]\n",
    "    y_test3 =  y_test_results[2]\n",
    "    predictions = (y_test1 + 3 * y_test2 + y_test3) / 5 \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melt Results\n",
    "\n",
    "This part is done since Kaggle doesn't allow a matrix solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_results(y_test):\n",
    "    return y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Melted Predictions to CSV\n",
    "\n",
    "This part converts predictions to CSV for uploading Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(predictions,filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['ID', 'predicted']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for i in range(len(predictions)):\n",
    "            writer.writerow({'ID': i, 'predicted': predictions[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1():\n",
    "    train_t0, train_t1, test_t0 = read_data_from_file()\n",
    "    ret_models = train_models(train_t0, train_t1)\n",
    "    predictions = test_models(test_t0, ret_models)\n",
    "    melted_results = melt_results(predictions)\n",
    "    write_to_file(melted_results,\"Kaggle_Submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Code With 5-fold CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(actual, predicted):\n",
    "    return mse(melt_results(predicted), melt_results(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(train_t0, train_t1):\n",
    "    kf = KFold(n_splits=5, random_state=r.seed(1), shuffle=True)\n",
    "    final_prediction = np.zeros(train_t0.shape[0]*595).reshape(train_t0.shape[0],595)\n",
    "    for train_index, test_index in kf.split(train_t0):\n",
    "        X_train, X_test = train_t0[train_index], train_t0[test_index]\n",
    "        y_train, y_test = train_t1[train_index], train_t1[test_index]\n",
    "        ret_models = train_models(X_train,y_train)\n",
    "        prediction = test_models(X_test,ret_models)\n",
    "        \n",
    "        for i in range(0, len(test_index)):\n",
    "            final_prediction[test_index[i],:] = prediction[i]\n",
    "        \n",
    "        mse = calculate_mse(y_test, prediction)\n",
    "        print(\"MSE: \",mse)\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_5fold():\n",
    "    train_t0,train_t1,test_t0 = read_data_from_file()\n",
    "    predictions = k_fold(train_t0, train_t1)\n",
    "    mse = calculate_mse(train_t1, predictions)\n",
    "    print(\"MSE of Overall: \",mse)\n",
    "    melted_results = melt_results(predictions)\n",
    "    write_to_file(melted_results,\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.002199392610051998\n",
      "MSE:  0.002393543799911158\n",
      "MSE:  0.0023079263995283376\n",
      "MSE:  0.003624242847320846\n",
      "MSE:  0.009352010501099461\n",
      "MSE of Overall:  0.0039754232315823606\n"
     ]
    }
   ],
   "source": [
    "q2_5fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
